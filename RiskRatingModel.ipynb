{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RiskRatingModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skjsourabh95/Machine-Learning/blob/master/RiskRatingModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2ZNkFPLUk31f",
        "colab_type": "code",
        "outputId": "d61f3b5b-6d3f-40f9-befd-2efef20435dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "#mounting the drive to get access to the files\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jOsj9sXVk7am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.externals import joblib\n",
        "# model building and pretesting with different classification models\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import json\n",
        "import os\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2NW_r_itNPo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Training the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwcahOCsnmVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_selection():\n",
        "  # Reading the dataset from a CSV file\n",
        "\n",
        "  data = pd.read_csv('/content/drive/My Drive/Data/modeling_inp.csv', encoding='utf-8')\n",
        "\n",
        "  #preprocessing\n",
        "\n",
        "  data.drop(['CUSTTYPE', 'STATUS','TXDATE_year'], axis=1,inplace=True)\n",
        "  data.drop(['CUSTNO.1', 'CUSTNO','ACCTNO'], axis=1,inplace=True)\n",
        "  data[['expValCashDepositsLow','expValCashDepositsHigh']] = data['expValCashDeposits'].str.split('-',1, expand=True)\n",
        "  data[['expTotalDepositsLow','expTotalDepositsHigh']] = data['expTotalDeposits'].str.split('-',1, expand=True)\n",
        "  data.drop(['expValCashDeposits','expTotalDeposits'], axis=1,inplace=True)\n",
        "  data[['expValCashDepositsLow','expValCashDepositsHigh','expTotalDepositsLow','expTotalDepositsHigh']] = data[['expValCashDepositsLow','expValCashDepositsHigh','expTotalDepositsLow','expTotalDepositsHigh']].apply(pd.to_numeric)\n",
        "  data['beneficiaryCountry'].fillna('No', inplace = True)\n",
        "\n",
        "  all_data=data.columns\n",
        "  numeric=data._get_numeric_data().columns\n",
        "  categorical=list(set(all_data)-set(numeric))\n",
        "  cols_need_mapped = categorical\n",
        "\n",
        "  mapper = {col: {cat: n for n, cat in enumerate(data[col].astype('category').cat.categories)} for col in data[cols_need_mapped]}\n",
        "\n",
        "  #saving the mapper in a dictionary\n",
        "  with open('categoricalEncoding.json', 'w') as fp:\n",
        "      json.dump(mapper,fp)\n",
        "  globals().update({'mapper':mapper})\n",
        "  \n",
        "  for c in cols_need_mapped :\n",
        "      data[c] = data[c].map(mapper[c])\n",
        "\n",
        "  sc = StandardScaler()\n",
        "  X =  pd.DataFrame(sc.fit_transform(data),columns=data.columns)\n",
        "  #spliting the dataset\n",
        "\n",
        "  X=data.loc[:, data.columns != 'riskRating']\n",
        "  y=data['riskRating']\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=45, stratify=y)\n",
        "\n",
        "  abc=[]\n",
        "  classifiers=[\"Nearest Neighbors\", \"Linear SVM\",\"Decision Tree\",\"Random Forest\",\"Naive Bayes\",\"QDA\",\"LogisticRegression\"]\n",
        "  models=[\n",
        "      KNeighborsClassifier(),## implements learning based on the k nearest neighbors of each query point, where k is an integer value specified by the user\n",
        "      LinearSVC(),## implements “one-vs-the-rest” multi-class strategy, thus training n_class models\n",
        "      DecisionTreeClassifier(max_depth = 3),## model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
        "      RandomForestClassifier(max_depth = 3),## fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting\n",
        "      GaussianNB(),## implements the Gaussian Naive Bayes algorithm for classification\n",
        "      QuadraticDiscriminantAnalysis(),## A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.\n",
        "      LogisticRegression()## implements regularized logistic regression using the ‘liblinear’ library\n",
        "  ]\n",
        "  for i in models:\n",
        "      model = i\n",
        "      model.fit(X_train, y_train)\n",
        "      abc.append(model.score(X_test,y_test))## score matches the results in y_test and y_pred and counts how many of them where true out of the total values\n",
        "  classifiers, abc,models = (list(t) for t in zip(*sorted(zip(classifiers, abc,models),key=lambda pair: pair[1],reverse=True)))    \n",
        "  models_dataframe=pd.DataFrame(abc,index=classifiers)   \n",
        "  models_dataframe.columns=['Score']\n",
        "\n",
        "  ## choosing the best scroring model\n",
        "  model=models[0]\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "THhdY0S2tEte",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model(model):\n",
        "  # Save model in the current working directory\n",
        "  model_file = \"risk_model.pkl\"  \n",
        "  joblib.dump(model, model_file)\n",
        "  globals().update({'model_file':model_file})\n",
        "  print(\"Model Saved in PWD\")\n",
        "  return model_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNeLjUcRx7X6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Making a wrapper pre-processing function to preprocess the new data and mapping its categorical columns\n",
        "def  preprocess(data,mapper):\n",
        "          \n",
        "      data.drop(['CUSTTYPE', 'STATUS','TXDATE_year'], axis=1,inplace=True)\n",
        "      data.drop(['CUSTNO.1', 'CUSTNO','ACCTNO'], axis=1,inplace=True)\n",
        "      \n",
        "      data[['expValCashDepositsLow','expValCashDepositsHigh']] = data['expValCashDeposits'].str.split('-',1, expand=True)\n",
        "      data[['expTotalDepositsLow','expTotalDepositsHigh']] = data['expTotalDeposits'].str.split('-',1, expand=True)\n",
        "      data.drop(['expValCashDeposits','expTotalDeposits'], axis=1,inplace=True)\n",
        "      data[['expValCashDepositsLow','expValCashDepositsHigh','expTotalDepositsLow','expTotalDepositsHigh']] = data[['expValCashDepositsLow','expValCashDepositsHigh','expTotalDepositsLow','expTotalDepositsHigh']].apply(pd.to_numeric)\n",
        "\n",
        "      \n",
        "      data['beneficiaryCountry'].fillna('India', inplace = True)\n",
        "                                        \n",
        "      all_data=data.columns\n",
        "      numeric=data._get_numeric_data().columns\n",
        "      categorical=list(set(all_data)-set(numeric))\n",
        "      \n",
        "      \n",
        "#       df_with_dummies = pd.get_dummies(data, prefix='Category_', columns=categorical)\n",
        "#       cols=df_with_dummies.columns\n",
        "      \n",
        "      cols_need_mapped = categorical\n",
        "\n",
        "      for c in cols_need_mapped :\n",
        "          data[c] = data[c].map(mapper[c])\n",
        "\n",
        "      sc = StandardScaler()\n",
        "      X =  pd.DataFrame(sc.fit_transform(data),columns=data.columns)\n",
        "      \n",
        "      return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gXwv1u_Kq_7j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predictRisk(model_file,data,mapper):\n",
        "  # Load model\n",
        "  risk_model = joblib.load(model_file)\n",
        "\n",
        "  #make prediction using model \n",
        "  new_data=pd.DataFrame(data,index=[0])\n",
        "  processed_data=preprocess(new_data,mapper)\n",
        "  riskRating=risk_model.predict(processed_data)[0]\n",
        "  return riskRating"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MqKLslKhyPLg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## new data which could be made as a dictionary or loaded from a json file\n",
        "data={\n",
        "    'CUSTNO':46678,\n",
        "    'Cr.Funds.Transfer.total':0, \n",
        "    'Cr.Payments.total':22222,\n",
        "    'Dr.Funds.Transfer.total':0, \n",
        "    'Cr.Funds.Transfer.count':0,\n",
        "    'Cr.Payments.count':1, \n",
        "    'Dr.Funds.Transfer.count':0, \n",
        "    'Dr.Payments.count':2,\n",
        "    'CUSTNO.1':45879,\n",
        "    'CUSTTYPE':1, \n",
        "    'ACCTNO':123456789, \n",
        "    'TYPEOFBUSINESS':'IT', \n",
        "    'COMPANYCAT':'Private',\n",
        "    'countryIncorporation':'India', \n",
        "    'countryTaxResidency':'India', \n",
        "    'addressBusinessCountry':'India',\n",
        "    'expValCashDeposits':'0-9000', \n",
        "    'expTotalDeposits':'0-33000', \n",
        "    'STATUS':'Active', \n",
        "    'AVAILBALANCE':460281.8224,\n",
        "    'prodCategory':'Loan', \n",
        "    'prodType':'Working Capital', \n",
        "    'productRisk':'Low', \n",
        "    'TXDATE_year':2015,\n",
        "    'CASHFLOWTYPE':'Dr', \n",
        "    'TXAMT':3187,\n",
        "    'beneficiaryCountry':'India', \n",
        "    'txnChannel':'Internet', \n",
        "    'txnMode':'Cash'\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlMjxobU1LEm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def driver():\n",
        "  if 'model_file' not in globals() or 'mapper' not in globals():\n",
        "    #training and selecting the model will run only the first time\n",
        "    model=model_selection()\n",
        "\n",
        "    #saving the model to pwd\n",
        "    model_file=save_model(model)\n",
        "    risk=predictRisk(model_file,data,globals().get('mapper'))\n",
        "    print(\"RiskRating for this Transaction is:\",risk)\n",
        "  else:\n",
        "    risk=predictRisk(globals().get('model_file'),data,globals().get('mapper'))\n",
        "    print(\"RiskRating for this Transaction is:\",risk)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Mt8gc-V1XML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb0643ef-c458-42ad-a2e7-83b06e193679"
      },
      "cell_type": "code",
      "source": [
        "## execute the driver to run the program\n",
        "driver()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RiskRating for this Transaction is: 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}